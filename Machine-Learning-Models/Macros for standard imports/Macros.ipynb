{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle table-like data and matrices\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Modelling Algorithms\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Modelling Helpers\n",
    "from sklearn.preprocessing import Normalizer , scale, LabelEncoder , StandardScaler ,MinMaxScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold, learning_curve , KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error,confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure visualisations\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [14,14]\n",
    "mpl.style.use( 'ggplot' )\n",
    "sns.set_style( 'whitegrid' )\n",
    "pylab.rcParams[ 'figure.figsize' ] = 12 , 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro -q __impC 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored '__impC' (Macro)\n"
     ]
    }
   ],
   "source": [
    "%store __impC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohit\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Rohit\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Rohit\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Rohit\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Rohit\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Handle table-like data and matrices\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Modelling Algorithms\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Modelling Helpers\n",
    "from sklearn.preprocessing import Normalizer , scale,StandardScaler,MinMaxScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold, learning_curve\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure visualisations\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [14,14]\n",
    "mpl.style.use( 'ggplot' )\n",
    "sns.set_style( 'whitegrid' )\n",
    "pylab.rcParams[ 'figure.figsize' ] = 12 , 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro -q __impR 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored '__impR' (Macro)\n"
     ]
    }
   ],
   "source": [
    "%store __impR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNKFC:\n",
    "    \n",
    "    def __init__(self, models, k,s):\n",
    "        self.models = models\n",
    "        self.k = k\n",
    "        self.s = s\n",
    "    \n",
    "    def fit(self,data,target):\n",
    "        kf = KFold(n_splits=self.k)\n",
    "        n1 = len(self.models)\n",
    "        L=0\n",
    "        for model in self.models:\n",
    "            n = len(model)\n",
    "            i=0\n",
    "            layer_accuracy = []\n",
    "            pred = pd.DataFrame()\n",
    "            for train_index , val_index in kf.split(data):\n",
    "                X_train , X_val = data.loc[train_index],data.loc[val_index]\n",
    "                y_train , y_val = target[train_index],target[val_index]\n",
    "                c= 0\n",
    "                while c < n:\n",
    "                    model[c].fit(X_train,y_train)\n",
    "                    pred[i] = model[c].predict(X_val)\n",
    "                    c=c+1\n",
    "                    i=i+1\n",
    "            for t in np.arange(kf.n_splits):\n",
    "                if t == 0:\n",
    "                    X = pred[np.arange(0,n)]\n",
    "                else:\n",
    "                    Y = pred[np.arange(t*n,(1+t)*n)].set_index(np.arange(t*int(data.shape[0]/kf.n_splits),(t+1)*int(data.shape[0]/kf.n_splits)))\n",
    "                    for g in np.arange(n):\n",
    "                        Y[g]=Y[(n*t)+g]\n",
    "                        Y = Y.drop(n*t+g,axis=1)\n",
    "                    X = pd.concat([X,Y])\n",
    "                    Y = Y.drop(np.arange(0,n),axis=1)\n",
    "            for v in np.arange(n):\n",
    "                layer_accuracy.append(accuracy_score(target,X[v]))\n",
    "                print(f'\\n Accuracy Score of Layer-{L} Model-{v} = {layer_accuracy[v]}')\n",
    "                print('--------------------------------------------------\\n')    \n",
    "            if self.s[L] == 1:\n",
    "                data = pd.concat([data,X],axis=1)\n",
    "            elif self.s[L] == 0:\n",
    "                data = X.copy()\n",
    "            L+=1\n",
    "            print(f'\\n Layer {L} Starts Here: --{L}--{L}--{L}--{L}--{L}--{L}--{L}--{L}--{L}--- \\n')\n",
    "    \n",
    "    def predict(self,data):\n",
    "        pred = pd.DataFrame()\n",
    "        for model in self.models:\n",
    "            for n in np.arange(len(model)): \n",
    "                pred[n] = model[n].predict(data)\n",
    "            data = pred.copy()\n",
    "            pred = pd.DataFrame()\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro -q __SNKFC 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored '__SNKFC' (Macro)\n"
     ]
    }
   ],
   "source": [
    "%store __SNKFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNKFR:\n",
    "    \n",
    "    def __init__(self, models, k,s):\n",
    "        self.models = models\n",
    "        self.k = k\n",
    "        self.s = s\n",
    "    \n",
    "    def fit(self,data,target):\n",
    "        kf = KFold(n_splits=self.k)\n",
    "        n1 = len(self.models)\n",
    "        L=0\n",
    "        for model in self.models:\n",
    "            n = len(model)\n",
    "            i=0\n",
    "            rmse = []\n",
    "            pred = pd.DataFrame()\n",
    "            for train_index , val_index in kf.split(data):\n",
    "                X_train , X_val = data.loc[train_index],data.loc[val_index]\n",
    "                y_train , y_val = target[train_index],target[val_index]\n",
    "                c= 0\n",
    "                while c < n:\n",
    "                    model[c].fit(X_train,y_train)\n",
    "                    pred[i] = model[c].predict(X_val)\n",
    "                    c=c+1\n",
    "                    i=i+1\n",
    "            for t in np.arange(kf.n_splits):\n",
    "                if t == 0:\n",
    "                    X = pred[np.arange(0,n)]\n",
    "                else:\n",
    "                    Y = pred[np.arange(t*n,(1+t)*n)].set_index(np.arange(t*int(data.shape[0]/kf.n_splits),(t+1)*int(data.shape[0]/kf.n_splits)))\n",
    "                    for g in np.arange(n):\n",
    "                        Y[g]=Y[(n*t)+g]\n",
    "                        Y = Y.drop(n*t+g,axis=1)\n",
    "                    X = pd.concat([X,Y])\n",
    "                    Y = Y.drop(np.arange(0,n),axis=1)\n",
    "            for v in np.arange(n):\n",
    "                rmse.append(np.sqrt(mean_squared_error(target,X[v])))\n",
    "                print(f'\\n RMS Error of Layer-{L} Model-{v} = {rmse[v]}')\n",
    "                print('--------------------------------------------------\\n')     \n",
    "            if L < len(self.s):\n",
    "                if self.s[L] == 1 :\n",
    "                    data = pd.concat([data,X],axis=1)\n",
    "                elif self.s[L] == 0:\n",
    "                    data = X.copy()\n",
    "                print(f'\\n Layer {L} Ends Here: --{L}--{L}--{L}--{L}--{L}--{L}--{L}--{L}--{L}--- \\n')    \n",
    "            L+=1\n",
    "    \n",
    "    def predict(self,data):\n",
    "        pred = pd.DataFrame()\n",
    "        L=0\n",
    "        for model in self.models:\n",
    "            for n in np.arange(len(model)): \n",
    "                pred[n] = model[n].predict(data) \n",
    "            if L == len(self.s):\n",
    "                return pred\n",
    "            else:\n",
    "                if self.s[L] == 1 :\n",
    "                    data = pd.concat([data,pred],axis=1)\n",
    "                elif self.s[L] == 0:\n",
    "                    data = pred.copy()\n",
    "                pred = pd.DataFrame()\n",
    "            L+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro -q __SNKFR 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored '__SNKFR' (Macro)\n"
     ]
    }
   ],
   "source": [
    "%store __SNKFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
